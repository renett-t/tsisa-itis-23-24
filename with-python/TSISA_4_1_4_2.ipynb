{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**4.1** ФОРМУЛИРОВКА <br/>\n",
    "Задана конфигурация нейронной сети для решения задачи регрессии y ~= g(x1, x2).\n",
    "![image.png](nn.png)\n",
    "\n",
    "<br/>\n",
    "Требуется обучить персептрон так, чтобы значение весов, при которых ошибка, вычисленная по формуле ![image.png](error_formula.png), не превышает 0,01."
   ],
   "metadata": {
    "id": "wvP3RSdaSSdQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "y = g(x1, x2) = f(h21 * w1 + h22 * w2 + h23 * w3) \n",
    "= f( f(h11 * v11 + h12 * v21) * w1 + f(h11 * v12 + h12 * v22) * w2 + f(h11 * v13 + h12 * v23) * w3)\n",
    "\n",
    "h11 = f(x1 * w11 + x2 * w21); \n",
    "h12 = f(x1 * w12 + x2 * w22);\n",
    "\n",
    "f - сигмоидная функция активации."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Нейронная сеть на входе имеет параметры x1 и x2.\n",
    "Будет три слоя, на выходе мы получаем y\n",
    "\n",
    "Первый слой: вычисление h11 и h12\n",
    "h11 = f(x1 * w11 + x2 * w21) где w11 это вес между x1 и h11, а w21 это вес между x12и h11\n",
    "h12 = f(x1 * w12 + x2 * w22) гду w12 вес мужду x1 и h12, а w22 это вес между x2 и h12\n",
    "\n",
    "Второй слой уже имеет h21, h22, h23\n",
    "h21 = f(h11 * v11 + h12 * v21) где v11 вес между h11 и h21, а v21 вес между h12 и h21\n",
    "h22 = f(h11 * v12 + h12 * v22) где v12 вес между h11 и h22, а v22 вес между h12 и h22\n",
    "h23 = f(h11 * v13 + h12 * v23) где v13 вес между h11 и h23, а v23 вес между h12 и h23\n",
    "\n",
    "На третьем слое получаем y\n",
    "y = f(h21 * w1 + h22 * w2 + h23 * w3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# Определение модели персептрона согласно заданным формулам\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class Perceptron(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Perceptron, self).__init__()\n",
    "        # Первый слой\n",
    "        self.h11 = nn.Linear(2, 1) # Один нейрон с двумя входами\n",
    "        self.h12 = nn.Linear(2, 1)\n",
    "        # Второй слой\n",
    "        self.h21 = nn.Linear(2, 1)\n",
    "        self.h22 = nn.Linear(2, 1)\n",
    "        self.h23 = nn.Linear(2, 1)\n",
    "        # Третий слой\n",
    "        self.w1 = nn.Parameter(torch.randn(1))\n",
    "        self.w2 = nn.Parameter(torch.randn(1))\n",
    "        self.w3 = nn.Parameter(torch.randn(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Первый слой\n",
    "        h11 = torch.sigmoid(self.h11(x))\n",
    "        h12 = torch.sigmoid(self.h12(x))\n",
    "        # Второй слой\n",
    "        h21_input = torch.cat([h11, h12], dim=1)\n",
    "        h21 = torch.sigmoid(self.h21(h21_input))\n",
    "        h22 = torch.sigmoid(self.h22(h21_input))\n",
    "        h23 = torch.sigmoid(self.h23(h21_input))\n",
    "        # Третий слой\n",
    "        y = torch.sigmoid(h21 * self.w1 + h22 * self.w2 + h23 * self.w3)\n",
    "        return y\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T10:24:35.113736Z",
     "start_time": "2023-12-16T10:24:35.075946Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# Создание модели, функции потерь и оптимизатора\n",
    "model = Perceptron()\n",
    "# среднеквадратичная ошибка (MSE) нейронной сети - то, что мы будем пытаться минимизировать\n",
    "criterion = nn.MSELoss()\n",
    "# стохастический градиентный спуск - функция для обновления весов\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T10:24:35.117171Z",
     "start_time": "2023-12-16T10:24:35.099196Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# Подготовка данных - создаем для PyTorch тензоры из данных чтобы использовать их в качестве входов для обучения.\n",
    "# Перед началом обучения данные стандартизируются или нормализуются.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "x_file = pd.read_csv('xdata.csv', delimiter=';')\n",
    "y_file = pd.read_csv('ydata03.csv')\n",
    "x = x_file.values\n",
    "y = y_file.values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T10:24:35.161236Z",
     "start_time": "2023-12-16T10:24:35.122692Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.2996     -0.15857864]\n",
      " [-0.2991     -0.12679492]\n",
      " [-0.2984     -0.1       ]\n",
      " [-0.2975     -0.0763932 ]\n",
      " [-0.2964     -0.05505103]\n",
      " [-0.2951     -0.03542487]\n",
      " [-0.2936     -0.01715729]\n",
      " [-0.2919      0.        ]\n",
      " [-0.29        0.01622777]\n",
      " [-0.2879      0.03166248]\n",
      " [-0.2856      0.04641016]\n",
      " [-0.2831      0.06055513]\n",
      " [-0.2804      0.07416574]\n",
      " [-0.2775      0.08729833]\n",
      " [-0.2744      0.1       ]\n",
      " [-0.2711      0.11231056]\n",
      " [-0.2676      0.12426407]\n",
      " [-0.2639      0.13588989]\n",
      " [-0.26        0.1472136 ]\n",
      " [-0.2559      0.15825757]\n",
      " [-0.2516      0.16904158]\n",
      " [-0.2471      0.17958315]\n",
      " [-0.2424      0.18989795]\n",
      " [-0.2375      0.2       ]\n",
      " [-0.2324      0.20990195]\n",
      " [-0.2271      0.21961524]\n",
      " [-0.2216      0.22915026]\n",
      " [-0.2159      0.23851648]\n",
      " [-0.21        0.24772256]\n",
      " [-0.2039      0.25677644]\n",
      " [-0.1976      0.26568542]\n",
      " [-0.1911      0.27445626]\n",
      " [-0.1844      0.28309519]\n",
      " [-0.1775      0.29160798]\n",
      " [-0.1704      0.3       ]\n",
      " [-0.1631      0.30827625]\n",
      " [-0.1556      0.3164414 ]\n",
      " [-0.1479      0.3244998 ]\n",
      " [-0.14        0.33245553]\n",
      " [-0.1319      0.34031242]\n",
      " [-0.1236      0.34807407]\n",
      " [-0.1151      0.35574385]\n",
      " [-0.1064      0.36332496]\n",
      " [-0.0975      0.37082039]\n",
      " [-0.0884      0.378233  ]\n",
      " [-0.0791      0.38556546]\n",
      " [-0.0696      0.39282032]\n",
      " [-0.0599      0.4       ]\n",
      " [-0.05        0.40710678]\n",
      " [-0.0399      0.41414284]\n",
      " [-0.0296      0.42111026]\n",
      " [-0.0191      0.42801099]\n",
      " [-0.0084      0.43484692]\n",
      " [ 0.0025      0.44161985]\n",
      " [ 0.0136      0.44833148]\n",
      " [ 0.0249      0.45498344]\n",
      " [ 0.0364      0.46157731]\n",
      " [ 0.0481      0.46811457]\n",
      " [ 0.06        0.47459667]\n",
      " [ 0.0721      0.48102497]\n",
      " [ 0.0844      0.48740079]\n",
      " [ 0.0969      0.49372539]\n",
      " [ 0.1096      0.5       ]\n",
      " [ 0.1225      0.50622577]\n",
      " [ 0.1356      0.51240384]\n",
      " [ 0.1489      0.51853528]\n",
      " [ 0.1624      0.52462113]\n",
      " [ 0.1761      0.53066239]\n",
      " [ 0.19        0.53666003]\n",
      " [ 0.2041      0.54261498]\n",
      " [ 0.2184      0.54852814]\n",
      " [ 0.2329      0.55440037]\n",
      " [ 0.2476      0.56023253]\n",
      " [ 0.2625      0.5660254 ]\n",
      " [ 0.2776      0.57177979]\n",
      " [ 0.2929      0.57749644]\n",
      " [ 0.3084      0.58317609]\n",
      " [ 0.3241      0.58881944]\n",
      " [ 0.34        0.59442719]\n",
      " [ 0.3561      0.6       ]\n",
      " [ 0.3724      0.60553851]\n",
      " [ 0.3889      0.61104336]\n",
      " [ 0.4056      0.61651514]\n",
      " [ 0.4225      0.62195445]\n",
      " [ 0.4396      0.62736185]\n",
      " [ 0.4569      0.63273791]\n",
      " [ 0.4744      0.63808315]\n",
      " [ 0.4921      0.64339811]\n",
      " [ 0.51        0.6486833 ]\n",
      " [ 0.5281      0.6539392 ]\n",
      " [ 0.5464      0.6591663 ]\n",
      " [ 0.5649      0.66436508]\n",
      " [ 0.5836      0.66953597]\n",
      " [ 0.6025      0.67467943]\n",
      " [ 0.6216      0.6797959 ]\n",
      " [ 0.6409      0.68488578]\n",
      " [ 0.6604      0.68994949]\n",
      " [ 0.6801      0.69498744]\n",
      " [ 0.7         0.7       ]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T10:24:35.165042Z",
     "start_time": "2023-12-16T10:24:35.149617Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.58966817]\n",
      " [0.59040073]\n",
      " [0.59102386]\n",
      " [0.59157832]\n",
      " [0.59208501]\n",
      " [0.59255636]\n",
      " [0.59300046]\n",
      " [0.59342294]\n",
      " [0.59382788]\n",
      " [0.59421838]\n",
      " [0.59459685]\n",
      " [0.59496518]\n",
      " [0.59532493]\n",
      " [0.59567737]\n",
      " [0.59602357]\n",
      " [0.59636442]\n",
      " [0.5967007 ]\n",
      " [0.59703307]\n",
      " [0.5973621 ]\n",
      " [0.5976883 ]\n",
      " [0.59801211]\n",
      " [0.59833393]\n",
      " [0.5986541 ]\n",
      " [0.59897293]\n",
      " [0.59929072]\n",
      " [0.59960771]\n",
      " [0.59992413]\n",
      " [0.60024019]\n",
      " [0.60055608]\n",
      " [0.60087197]\n",
      " [0.60118802]\n",
      " [0.60150437]\n",
      " [0.60182117]\n",
      " [0.60213852]\n",
      " [0.60245654]\n",
      " [0.60277534]\n",
      " [0.60309502]\n",
      " [0.60341565]\n",
      " [0.60373732]\n",
      " [0.60406012]\n",
      " [0.6043841 ]\n",
      " [0.60470933]\n",
      " [0.60503587]\n",
      " [0.60536378]\n",
      " [0.60569311]\n",
      " [0.6060239 ]\n",
      " [0.6063562 ]\n",
      " [0.60669005]\n",
      " [0.60702548]\n",
      " [0.60736253]\n",
      " [0.60770122]\n",
      " [0.6080416 ]\n",
      " [0.60838367]\n",
      " [0.60872747]\n",
      " [0.609073  ]\n",
      " [0.60942031]\n",
      " [0.60976938]\n",
      " [0.61012025]\n",
      " [0.61047293]\n",
      " [0.61082741]\n",
      " [0.61118372]\n",
      " [0.61154185]\n",
      " [0.61190181]\n",
      " [0.61226361]\n",
      " [0.61262725]\n",
      " [0.61299271]\n",
      " [0.61336002]\n",
      " [0.61372915]\n",
      " [0.6141001 ]\n",
      " [0.61447288]\n",
      " [0.61484746]\n",
      " [0.61522385]\n",
      " [0.61560203]\n",
      " [0.615982  ]\n",
      " [0.61636373]\n",
      " [0.61674721]\n",
      " [0.61713243]\n",
      " [0.61751938]\n",
      " [0.61790803]\n",
      " [0.61829837]\n",
      " [0.61869038]\n",
      " [0.61908404]\n",
      " [0.61947932]\n",
      " [0.61987621]\n",
      " [0.62027467]\n",
      " [0.62067469]\n",
      " [0.62107624]\n",
      " [0.62147929]\n",
      " [0.62188381]\n",
      " [0.62228978]\n",
      " [0.62269717]\n",
      " [0.62310595]\n",
      " [0.62351608]\n",
      " [0.62392753]\n",
      " [0.62434028]\n",
      " [0.62475428]\n",
      " [0.62516951]\n",
      " [0.62558592]\n",
      " [0.62600349]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T10:24:35.211794Z",
     "start_time": "2023-12-16T10:24:35.171221Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Разбиваем на тестовую и тренировочную выборки 85/15\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T10:24:35.215444Z",
     "start_time": "2023-12-16T10:24:35.189213Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T10:24:35.236359Z",
     "start_time": "2023-12-16T10:24:35.221434Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# ... (ваш код стандартизации/нормализации данных, если требуется)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T10:24:35.266325Z",
     "start_time": "2023-12-16T10:24:35.241062Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Создание DataLoader для обучения\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T10:24:35.269715Z",
     "start_time": "2023-12-16T10:24:35.250352Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.12097789347171783\n",
      "Epoch 2, Loss: 0.12062125653028488\n",
      "Epoch 3, Loss: 0.12026519328355789\n",
      "Epoch 4, Loss: 0.11990942060947418\n",
      "Epoch 5, Loss: 0.1195545569062233\n",
      "Epoch 6, Loss: 0.11919926851987839\n",
      "Epoch 7, Loss: 0.11884479969739914\n",
      "Epoch 8, Loss: 0.11849106103181839\n",
      "Epoch 9, Loss: 0.11813797056674957\n",
      "Epoch 10, Loss: 0.11778541654348373\n",
      "Epoch 11, Loss: 0.11743387579917908\n",
      "Epoch 12, Loss: 0.11708211898803711\n",
      "Epoch 13, Loss: 0.11673126369714737\n",
      "Epoch 14, Loss: 0.11638106405735016\n",
      "Epoch 15, Loss: 0.11603205651044846\n",
      "Epoch 16, Loss: 0.11568371951580048\n",
      "Epoch 17, Loss: 0.11533588916063309\n",
      "Epoch 18, Loss: 0.11498809605836868\n",
      "Epoch 19, Loss: 0.11464045196771622\n",
      "Epoch 20, Loss: 0.114293672144413\n",
      "Epoch 21, Loss: 0.1139475554227829\n",
      "Epoch 22, Loss: 0.11360166221857071\n",
      "Epoch 23, Loss: 0.11325657367706299\n",
      "Epoch 24, Loss: 0.11291210353374481\n",
      "Epoch 25, Loss: 0.11256781220436096\n",
      "Epoch 26, Loss: 0.11222425848245621\n",
      "Epoch 27, Loss: 0.11188183724880219\n",
      "Epoch 28, Loss: 0.11153949797153473\n",
      "Epoch 29, Loss: 0.11119801551103592\n",
      "Epoch 30, Loss: 0.11085701733827591\n",
      "Epoch 31, Loss: 0.11051636189222336\n",
      "Epoch 32, Loss: 0.11017625033855438\n",
      "Epoch 33, Loss: 0.10983724147081375\n",
      "Epoch 34, Loss: 0.10949885845184326\n",
      "Epoch 35, Loss: 0.10916092246770859\n",
      "Epoch 36, Loss: 0.10882420837879181\n",
      "Epoch 37, Loss: 0.10848750919103622\n",
      "Epoch 38, Loss: 0.1081509068608284\n",
      "Epoch 39, Loss: 0.10781501233577728\n",
      "Epoch 40, Loss: 0.10748039931058884\n",
      "Epoch 41, Loss: 0.10714732110500336\n",
      "Epoch 42, Loss: 0.10681327432394028\n",
      "Epoch 43, Loss: 0.10648069530725479\n",
      "Epoch 44, Loss: 0.10614807903766632\n",
      "Epoch 45, Loss: 0.10581596195697784\n",
      "Epoch 46, Loss: 0.10548437386751175\n",
      "Epoch 47, Loss: 0.10515369474887848\n",
      "Epoch 48, Loss: 0.10482368618249893\n",
      "Epoch 49, Loss: 0.10449448227882385\n",
      "Epoch 50, Loss: 0.10416555404663086\n",
      "Epoch 51, Loss: 0.10383794456720352\n",
      "Epoch 52, Loss: 0.10351022332906723\n",
      "Epoch 53, Loss: 0.10318335145711899\n",
      "Epoch 54, Loss: 0.10285701602697372\n",
      "Epoch 55, Loss: 0.10253171622753143\n",
      "Epoch 56, Loss: 0.10220663249492645\n",
      "Epoch 57, Loss: 0.1018819808959961\n",
      "Epoch 58, Loss: 0.10155852138996124\n",
      "Epoch 59, Loss: 0.1012357622385025\n",
      "Epoch 60, Loss: 0.10091368854045868\n",
      "Epoch 61, Loss: 0.10059169679880142\n",
      "Epoch 62, Loss: 0.1002705842256546\n",
      "Epoch 63, Loss: 0.09994986653327942\n",
      "Epoch 64, Loss: 0.09963032603263855\n",
      "Epoch 65, Loss: 0.09931150823831558\n",
      "Epoch 66, Loss: 0.09899375587701797\n",
      "Epoch 67, Loss: 0.09867670387029648\n",
      "Epoch 68, Loss: 0.0983598381280899\n",
      "Epoch 69, Loss: 0.09804318100214005\n",
      "Epoch 70, Loss: 0.0977274477481842\n",
      "Epoch 71, Loss: 0.09741225838661194\n",
      "Epoch 72, Loss: 0.09709835052490234\n",
      "Epoch 73, Loss: 0.09678444266319275\n",
      "Epoch 74, Loss: 0.0964711531996727\n",
      "Epoch 75, Loss: 0.09615863114595413\n",
      "Epoch 76, Loss: 0.09584708511829376\n",
      "Epoch 77, Loss: 0.09553636610507965\n",
      "Epoch 78, Loss: 0.09522616863250732\n",
      "Epoch 79, Loss: 0.09491712599992752\n",
      "Epoch 80, Loss: 0.09460772573947906\n",
      "Epoch 81, Loss: 0.09429951757192612\n",
      "Epoch 82, Loss: 0.09399224817752838\n",
      "Epoch 83, Loss: 0.09368542581796646\n",
      "Epoch 84, Loss: 0.09337922930717468\n",
      "Epoch 85, Loss: 0.09307365864515305\n",
      "Epoch 86, Loss: 0.09276928752660751\n",
      "Epoch 87, Loss: 0.09246515482664108\n",
      "Epoch 88, Loss: 0.09216161072254181\n",
      "Epoch 89, Loss: 0.09185957163572311\n",
      "Epoch 90, Loss: 0.09155724197626114\n",
      "Epoch 91, Loss: 0.0912562683224678\n",
      "Epoch 92, Loss: 0.09095551073551178\n",
      "Epoch 93, Loss: 0.09065519273281097\n",
      "Epoch 94, Loss: 0.09035583585500717\n",
      "Epoch 95, Loss: 0.09005727618932724\n",
      "Epoch 96, Loss: 0.0897597223520279\n",
      "Epoch 97, Loss: 0.08946280926465988\n",
      "Epoch 98, Loss: 0.08916699141263962\n",
      "Epoch 99, Loss: 0.08887190371751785\n",
      "Epoch 100, Loss: 0.08857704699039459\n",
      "Epoch 101, Loss: 0.08828244358301163\n",
      "Epoch 102, Loss: 0.08798858523368835\n",
      "Epoch 103, Loss: 0.08769576251506805\n",
      "Epoch 104, Loss: 0.0874035432934761\n",
      "Epoch 105, Loss: 0.0871124342083931\n",
      "Epoch 106, Loss: 0.0868215262889862\n",
      "Epoch 107, Loss: 0.08653152734041214\n",
      "Epoch 108, Loss: 0.0862421840429306\n",
      "Epoch 109, Loss: 0.08595356345176697\n",
      "Epoch 110, Loss: 0.0856654942035675\n",
      "Epoch 111, Loss: 0.0853780061006546\n",
      "Epoch 112, Loss: 0.0850914865732193\n",
      "Epoch 113, Loss: 0.08480573445558548\n",
      "Epoch 114, Loss: 0.08452031761407852\n",
      "Epoch 115, Loss: 0.08423557877540588\n",
      "Epoch 116, Loss: 0.08395207673311234\n",
      "Epoch 117, Loss: 0.08366963267326355\n",
      "Epoch 118, Loss: 0.08338797837495804\n",
      "Epoch 119, Loss: 0.08310676366090775\n",
      "Epoch 120, Loss: 0.0828259214758873\n",
      "Epoch 121, Loss: 0.08254604786634445\n",
      "Epoch 122, Loss: 0.08226694911718369\n",
      "Epoch 123, Loss: 0.08198840171098709\n",
      "Epoch 124, Loss: 0.0817108079791069\n",
      "Epoch 125, Loss: 0.08143417537212372\n",
      "Epoch 126, Loss: 0.08115711063146591\n",
      "Epoch 127, Loss: 0.08088191598653793\n",
      "Epoch 128, Loss: 0.08060682564973831\n",
      "Epoch 129, Loss: 0.08033294975757599\n",
      "Epoch 130, Loss: 0.0800592228770256\n",
      "Epoch 131, Loss: 0.07978619635105133\n",
      "Epoch 132, Loss: 0.07951437681913376\n",
      "Epoch 133, Loss: 0.07924332469701767\n",
      "Epoch 134, Loss: 0.07897314429283142\n",
      "Epoch 135, Loss: 0.07870306074619293\n",
      "Epoch 136, Loss: 0.0784340351819992\n",
      "Epoch 137, Loss: 0.07816581428050995\n",
      "Epoch 138, Loss: 0.07789789885282516\n",
      "Epoch 139, Loss: 0.0776306763291359\n",
      "Epoch 140, Loss: 0.07736445963382721\n",
      "Epoch 141, Loss: 0.07709915935993195\n",
      "Epoch 142, Loss: 0.07683485001325607\n",
      "Epoch 143, Loss: 0.07657046616077423\n",
      "Epoch 144, Loss: 0.07630719244480133\n",
      "Epoch 145, Loss: 0.07604435086250305\n",
      "Epoch 146, Loss: 0.07578207552433014\n",
      "Epoch 147, Loss: 0.07552099972963333\n",
      "Epoch 148, Loss: 0.07526051253080368\n",
      "Epoch 149, Loss: 0.0750005692243576\n",
      "Epoch 150, Loss: 0.07474154978990555\n",
      "Epoch 151, Loss: 0.07448355853557587\n",
      "Epoch 152, Loss: 0.07422570884227753\n",
      "Epoch 153, Loss: 0.07396876811981201\n",
      "Epoch 154, Loss: 0.07371271401643753\n",
      "Epoch 155, Loss: 0.07345690578222275\n",
      "Epoch 156, Loss: 0.07320184260606766\n",
      "Epoch 157, Loss: 0.07294787466526031\n",
      "Epoch 158, Loss: 0.0726945549249649\n",
      "Epoch 159, Loss: 0.0724414810538292\n",
      "Epoch 160, Loss: 0.07218943536281586\n",
      "Epoch 161, Loss: 0.0719384029507637\n",
      "Epoch 162, Loss: 0.07168761640787125\n",
      "Epoch 163, Loss: 0.07143820077180862\n",
      "Epoch 164, Loss: 0.07118882238864899\n",
      "Epoch 165, Loss: 0.07094048708677292\n",
      "Epoch 166, Loss: 0.07069303095340729\n",
      "Epoch 167, Loss: 0.07044621556997299\n",
      "Epoch 168, Loss: 0.07020001858472824\n",
      "Epoch 169, Loss: 0.06995491683483124\n",
      "Epoch 170, Loss: 0.06970974057912827\n",
      "Epoch 171, Loss: 0.0694659873843193\n",
      "Epoch 172, Loss: 0.06922242045402527\n",
      "Epoch 173, Loss: 0.06897939741611481\n",
      "Epoch 174, Loss: 0.06873729825019836\n",
      "Epoch 175, Loss: 0.06849579513072968\n",
      "Epoch 176, Loss: 0.06825533509254456\n",
      "Epoch 177, Loss: 0.06801538914442062\n",
      "Epoch 178, Loss: 0.06777636706829071\n",
      "Epoch 179, Loss: 0.06753763556480408\n",
      "Epoch 180, Loss: 0.06729957461357117\n",
      "Epoch 181, Loss: 0.06706202775239944\n",
      "Epoch 182, Loss: 0.06682561337947845\n",
      "Epoch 183, Loss: 0.06658986210823059\n",
      "Epoch 184, Loss: 0.0663551315665245\n",
      "Epoch 185, Loss: 0.06612063199281693\n",
      "Epoch 186, Loss: 0.06588699668645859\n",
      "Epoch 187, Loss: 0.06565428525209427\n",
      "Epoch 188, Loss: 0.06542227417230606\n",
      "Epoch 189, Loss: 0.06519105285406113\n",
      "Epoch 190, Loss: 0.06496014446020126\n",
      "Epoch 191, Loss: 0.06472984701395035\n",
      "Epoch 192, Loss: 0.06450055539608002\n",
      "Epoch 193, Loss: 0.06427151709794998\n",
      "Epoch 194, Loss: 0.06404338777065277\n",
      "Epoch 195, Loss: 0.06381597369909286\n",
      "Epoch 196, Loss: 0.06358936429023743\n",
      "Epoch 197, Loss: 0.06336352974176407\n",
      "Epoch 198, Loss: 0.0631379783153534\n",
      "Epoch 199, Loss: 0.06291329860687256\n",
      "Epoch 200, Loss: 0.06268937885761261\n",
      "Epoch 201, Loss: 0.06246602162718773\n",
      "Epoch 202, Loss: 0.06224321946501732\n",
      "Epoch 203, Loss: 0.06202152743935585\n",
      "Epoch 204, Loss: 0.06180014833807945\n",
      "Epoch 205, Loss: 0.06157948821783066\n",
      "Epoch 206, Loss: 0.06135990470647812\n",
      "Epoch 207, Loss: 0.061140332370996475\n",
      "Epoch 208, Loss: 0.0609222836792469\n",
      "Epoch 209, Loss: 0.06070432811975479\n",
      "Epoch 210, Loss: 0.0604870468378067\n",
      "Epoch 211, Loss: 0.06027062609791756\n",
      "Epoch 212, Loss: 0.06005454435944557\n",
      "Epoch 213, Loss: 0.05983898788690567\n",
      "Epoch 214, Loss: 0.0596243292093277\n",
      "Epoch 215, Loss: 0.05941026657819748\n",
      "Epoch 216, Loss: 0.0591970719397068\n",
      "Epoch 217, Loss: 0.05898484215140343\n",
      "Epoch 218, Loss: 0.05877311900258064\n",
      "Epoch 219, Loss: 0.05856195464730263\n",
      "Epoch 220, Loss: 0.058351289480924606\n",
      "Epoch 221, Loss: 0.05814192816615105\n",
      "Epoch 222, Loss: 0.057932619005441666\n",
      "Epoch 223, Loss: 0.0577242411673069\n",
      "Epoch 224, Loss: 0.05751674622297287\n",
      "Epoch 225, Loss: 0.05730960890650749\n",
      "Epoch 226, Loss: 0.05710294470191002\n",
      "Epoch 227, Loss: 0.056897521018981934\n",
      "Epoch 228, Loss: 0.0566922165453434\n",
      "Epoch 229, Loss: 0.05648770555853844\n",
      "Epoch 230, Loss: 0.05628371238708496\n",
      "Epoch 231, Loss: 0.056080617010593414\n",
      "Epoch 232, Loss: 0.055878058075904846\n",
      "Epoch 233, Loss: 0.055675704032182693\n",
      "Epoch 234, Loss: 0.055474650114774704\n",
      "Epoch 235, Loss: 0.05527346208691597\n",
      "Epoch 236, Loss: 0.055073536932468414\n",
      "Epoch 237, Loss: 0.05487442389130592\n",
      "Epoch 238, Loss: 0.054675888270139694\n",
      "Epoch 239, Loss: 0.05447795242071152\n",
      "Epoch 240, Loss: 0.054280199110507965\n",
      "Epoch 241, Loss: 0.05408349260687828\n",
      "Epoch 242, Loss: 0.053886983543634415\n",
      "Epoch 243, Loss: 0.05369184538722038\n",
      "Epoch 244, Loss: 0.05349721387028694\n",
      "Epoch 245, Loss: 0.0533033050596714\n",
      "Epoch 246, Loss: 0.05310940742492676\n",
      "Epoch 247, Loss: 0.052916355431079865\n",
      "Epoch 248, Loss: 0.05272381007671356\n",
      "Epoch 249, Loss: 0.05253184214234352\n",
      "Epoch 250, Loss: 0.0523407980799675\n",
      "Epoch 251, Loss: 0.05215020850300789\n",
      "Epoch 252, Loss: 0.05196025222539902\n",
      "Epoch 253, Loss: 0.05177108570933342\n",
      "Epoch 254, Loss: 0.0515822172164917\n",
      "Epoch 255, Loss: 0.051394566893577576\n",
      "Epoch 256, Loss: 0.05120724067091942\n",
      "Epoch 257, Loss: 0.0510205440223217\n",
      "Epoch 258, Loss: 0.05083448439836502\n",
      "Epoch 259, Loss: 0.05064859613776207\n",
      "Epoch 260, Loss: 0.05046356841921806\n",
      "Epoch 261, Loss: 0.0502794049680233\n",
      "Epoch 262, Loss: 0.050095975399017334\n",
      "Epoch 263, Loss: 0.049912650138139725\n",
      "Epoch 264, Loss: 0.0497303269803524\n",
      "Epoch 265, Loss: 0.049548324197530746\n",
      "Epoch 266, Loss: 0.049367133527994156\n",
      "Epoch 267, Loss: 0.049186401069164276\n",
      "Epoch 268, Loss: 0.049006421118974686\n",
      "Epoch 269, Loss: 0.0488266721367836\n",
      "Epoch 270, Loss: 0.0486479178071022\n",
      "Epoch 271, Loss: 0.04846932366490364\n",
      "Epoch 272, Loss: 0.0482916422188282\n",
      "Epoch 273, Loss: 0.04811431095004082\n",
      "Epoch 274, Loss: 0.04793797433376312\n",
      "Epoch 275, Loss: 0.04776190221309662\n",
      "Epoch 276, Loss: 0.04758612439036369\n",
      "Epoch 277, Loss: 0.04741155728697777\n",
      "Epoch 278, Loss: 0.04723712429404259\n",
      "Epoch 279, Loss: 0.04706351086497307\n",
      "Epoch 280, Loss: 0.04689045622944832\n",
      "Epoch 281, Loss: 0.04671787470579147\n",
      "Epoch 282, Loss: 0.046546224504709244\n",
      "Epoch 283, Loss: 0.0463750921189785\n",
      "Epoch 284, Loss: 0.04620446264743805\n",
      "Epoch 285, Loss: 0.046034444123506546\n",
      "Epoch 286, Loss: 0.04586492478847504\n",
      "Epoch 287, Loss: 0.04569622129201889\n",
      "Epoch 288, Loss: 0.04552764073014259\n",
      "Epoch 289, Loss: 0.04536021873354912\n",
      "Epoch 290, Loss: 0.04519282653927803\n",
      "Epoch 291, Loss: 0.0450262613594532\n",
      "Epoch 292, Loss: 0.04485999047756195\n",
      "Epoch 293, Loss: 0.044694434851408005\n",
      "Epoch 294, Loss: 0.04452994838356972\n",
      "Epoch 295, Loss: 0.04436574503779411\n",
      "Epoch 296, Loss: 0.044201768934726715\n",
      "Epoch 297, Loss: 0.0440388098359108\n",
      "Epoch 298, Loss: 0.04387662559747696\n",
      "Epoch 299, Loss: 0.04371415823698044\n",
      "Epoch 300, Loss: 0.04355268180370331\n",
      "Epoch 301, Loss: 0.043391790241003036\n",
      "Epoch 302, Loss: 0.043231699615716934\n",
      "Epoch 303, Loss: 0.043071843683719635\n",
      "Epoch 304, Loss: 0.042912278324365616\n",
      "Epoch 305, Loss: 0.04275345429778099\n",
      "Epoch 306, Loss: 0.04259522631764412\n",
      "Epoch 307, Loss: 0.04243776574730873\n",
      "Epoch 308, Loss: 0.042280323803424835\n",
      "Epoch 309, Loss: 0.04212368279695511\n",
      "Epoch 310, Loss: 0.041967280209064484\n",
      "Epoch 311, Loss: 0.041812025010585785\n",
      "Epoch 312, Loss: 0.04165694862604141\n",
      "Epoch 313, Loss: 0.041502341628074646\n",
      "Epoch 314, Loss: 0.04134859889745712\n",
      "Epoch 315, Loss: 0.04119507595896721\n",
      "Epoch 316, Loss: 0.04104198142886162\n",
      "Epoch 317, Loss: 0.04088926315307617\n",
      "Epoch 318, Loss: 0.040737334638834\n",
      "Epoch 319, Loss: 0.040586069226264954\n",
      "Epoch 320, Loss: 0.040435172617435455\n",
      "Epoch 321, Loss: 0.04028518870472908\n",
      "Epoch 322, Loss: 0.040135063230991364\n",
      "Epoch 323, Loss: 0.03998579457402229\n",
      "Epoch 324, Loss: 0.03983689472079277\n",
      "Epoch 325, Loss: 0.039688799530267715\n",
      "Epoch 326, Loss: 0.0395408533513546\n",
      "Epoch 327, Loss: 0.039393600076436996\n",
      "Epoch 328, Loss: 0.03924738988280296\n",
      "Epoch 329, Loss: 0.03910114988684654\n",
      "Epoch 330, Loss: 0.038956042379140854\n",
      "Epoch 331, Loss: 0.0388113409280777\n",
      "Epoch 332, Loss: 0.03866706043481827\n",
      "Epoch 333, Loss: 0.03852309286594391\n",
      "Epoch 334, Loss: 0.03837975487112999\n",
      "Epoch 335, Loss: 0.03823653981089592\n",
      "Epoch 336, Loss: 0.038094062358140945\n",
      "Epoch 337, Loss: 0.03795221075415611\n",
      "Epoch 338, Loss: 0.03781089559197426\n",
      "Epoch 339, Loss: 0.03766985982656479\n",
      "Epoch 340, Loss: 0.03752923756837845\n",
      "Epoch 341, Loss: 0.03738931939005852\n",
      "Epoch 342, Loss: 0.03725011646747589\n",
      "Epoch 343, Loss: 0.03711078688502312\n",
      "Epoch 344, Loss: 0.03697230666875839\n",
      "Epoch 345, Loss: 0.03683382272720337\n",
      "Epoch 346, Loss: 0.03669602796435356\n",
      "Epoch 347, Loss: 0.036558739840984344\n",
      "Epoch 348, Loss: 0.03642203286290169\n",
      "Epoch 349, Loss: 0.0362856462597847\n",
      "Epoch 350, Loss: 0.03614990785717964\n",
      "Epoch 351, Loss: 0.036014799028635025\n",
      "Epoch 352, Loss: 0.03587982431054115\n",
      "Epoch 353, Loss: 0.03574583679437637\n",
      "Epoch 354, Loss: 0.03561209887266159\n",
      "Epoch 355, Loss: 0.03547867015004158\n",
      "Epoch 356, Loss: 0.035346098244190216\n",
      "Epoch 357, Loss: 0.03521428257226944\n",
      "Epoch 358, Loss: 0.03508227691054344\n",
      "Epoch 359, Loss: 0.0349508672952652\n",
      "Epoch 360, Loss: 0.03482013940811157\n",
      "Epoch 361, Loss: 0.034689512103796005\n",
      "Epoch 362, Loss: 0.0345599539577961\n",
      "Epoch 363, Loss: 0.03443053737282753\n",
      "Epoch 364, Loss: 0.03430156037211418\n",
      "Epoch 365, Loss: 0.034172412008047104\n",
      "Epoch 366, Loss: 0.03404422849416733\n",
      "Epoch 367, Loss: 0.033916912972927094\n",
      "Epoch 368, Loss: 0.03378990665078163\n",
      "Epoch 369, Loss: 0.03366357460618019\n",
      "Epoch 370, Loss: 0.03353743627667427\n",
      "Epoch 371, Loss: 0.03341156989336014\n",
      "Epoch 372, Loss: 0.03328632935881615\n",
      "Epoch 373, Loss: 0.03316137567162514\n",
      "Epoch 374, Loss: 0.03303682059049606\n",
      "Epoch 375, Loss: 0.032913174480199814\n",
      "Epoch 376, Loss: 0.032789524644613266\n",
      "Epoch 377, Loss: 0.03266642615199089\n",
      "Epoch 378, Loss: 0.032543063163757324\n",
      "Epoch 379, Loss: 0.03242109343409538\n",
      "Epoch 380, Loss: 0.03229966387152672\n",
      "Epoch 381, Loss: 0.03217846527695656\n",
      "Epoch 382, Loss: 0.032057419419288635\n",
      "Epoch 383, Loss: 0.03193682059645653\n",
      "Epoch 384, Loss: 0.03181711956858635\n",
      "Epoch 385, Loss: 0.0316973440349102\n",
      "Epoch 386, Loss: 0.03157841041684151\n",
      "Epoch 387, Loss: 0.03145941346883774\n",
      "Epoch 388, Loss: 0.03134092316031456\n",
      "Epoch 389, Loss: 0.031222974881529808\n",
      "Epoch 390, Loss: 0.03110569342970848\n",
      "Epoch 391, Loss: 0.03098900243639946\n",
      "Epoch 392, Loss: 0.03087228164076805\n",
      "Epoch 393, Loss: 0.030755994841456413\n",
      "Epoch 394, Loss: 0.03064017742872238\n",
      "Epoch 395, Loss: 0.030524637550115585\n",
      "Epoch 396, Loss: 0.030409492552280426\n",
      "Epoch 397, Loss: 0.030295098200440407\n",
      "Epoch 398, Loss: 0.030180979520082474\n",
      "Epoch 399, Loss: 0.0300675630569458\n",
      "Epoch 400, Loss: 0.029954660683870316\n",
      "Epoch 401, Loss: 0.02984209544956684\n",
      "Epoch 402, Loss: 0.02972939983010292\n",
      "Epoch 403, Loss: 0.02961691841483116\n",
      "Epoch 404, Loss: 0.029505278915166855\n",
      "Epoch 405, Loss: 0.029394041746854782\n",
      "Epoch 406, Loss: 0.029283082112669945\n",
      "Epoch 407, Loss: 0.02917276695370674\n",
      "Epoch 408, Loss: 0.029062844812870026\n",
      "Epoch 409, Loss: 0.028953103348612785\n",
      "Epoch 410, Loss: 0.028843948617577553\n",
      "Epoch 411, Loss: 0.028735101222991943\n",
      "Epoch 412, Loss: 0.028627019375562668\n",
      "Epoch 413, Loss: 0.028518907725811005\n",
      "Epoch 414, Loss: 0.02841132879257202\n",
      "Epoch 415, Loss: 0.028304006904363632\n",
      "Epoch 416, Loss: 0.02819698490202427\n",
      "Epoch 417, Loss: 0.02809029072523117\n",
      "Epoch 418, Loss: 0.02798444591462612\n",
      "Epoch 419, Loss: 0.02787880040705204\n",
      "Epoch 420, Loss: 0.02777356654405594\n",
      "Epoch 421, Loss: 0.027668874710798264\n",
      "Epoch 422, Loss: 0.0275646410882473\n",
      "Epoch 423, Loss: 0.027460400015115738\n",
      "Epoch 424, Loss: 0.027356691658496857\n",
      "Epoch 425, Loss: 0.02725333720445633\n",
      "Epoch 426, Loss: 0.02715054340660572\n",
      "Epoch 427, Loss: 0.027047598734498024\n",
      "Epoch 428, Loss: 0.0269454512745142\n",
      "Epoch 429, Loss: 0.026843437924981117\n",
      "Epoch 430, Loss: 0.026742050424218178\n",
      "Epoch 431, Loss: 0.0266408808529377\n",
      "Epoch 432, Loss: 0.026540309190750122\n",
      "Epoch 433, Loss: 0.026439666748046875\n",
      "Epoch 434, Loss: 0.02633984573185444\n",
      "Epoch 435, Loss: 0.02624020352959633\n",
      "Epoch 436, Loss: 0.026140904054045677\n",
      "Epoch 437, Loss: 0.026042070239782333\n",
      "Epoch 438, Loss: 0.025943957269191742\n",
      "Epoch 439, Loss: 0.025845995172858238\n",
      "Epoch 440, Loss: 0.025748170912265778\n",
      "Epoch 441, Loss: 0.025650648400187492\n",
      "Epoch 442, Loss: 0.025553716346621513\n",
      "Epoch 443, Loss: 0.025457091629505157\n",
      "Epoch 444, Loss: 0.02536066062748432\n",
      "Epoch 445, Loss: 0.025264684110879898\n",
      "Epoch 446, Loss: 0.025169111788272858\n",
      "Epoch 447, Loss: 0.02507394179701805\n",
      "Epoch 448, Loss: 0.024979202076792717\n",
      "Epoch 449, Loss: 0.024884359911084175\n",
      "Epoch 450, Loss: 0.024790091440081596\n",
      "Epoch 451, Loss: 0.02469632215797901\n",
      "Epoch 452, Loss: 0.024602659046649933\n",
      "Epoch 453, Loss: 0.024509338662028313\n",
      "Epoch 454, Loss: 0.024416379630565643\n",
      "Epoch 455, Loss: 0.024323808029294014\n",
      "Epoch 456, Loss: 0.02423213981091976\n",
      "Epoch 457, Loss: 0.024140778928995132\n",
      "Epoch 458, Loss: 0.024049129337072372\n",
      "Epoch 459, Loss: 0.02395802177488804\n",
      "Epoch 460, Loss: 0.023867281153798103\n",
      "Epoch 461, Loss: 0.023776870220899582\n",
      "Epoch 462, Loss: 0.02368668094277382\n",
      "Epoch 463, Loss: 0.023597439751029015\n",
      "Epoch 464, Loss: 0.023508330807089806\n",
      "Epoch 465, Loss: 0.023419233039021492\n",
      "Epoch 466, Loss: 0.023330317810177803\n",
      "Epoch 467, Loss: 0.023242102935910225\n",
      "Epoch 468, Loss: 0.02315415069460869\n",
      "Epoch 469, Loss: 0.023066610097885132\n",
      "Epoch 470, Loss: 0.02297891303896904\n",
      "Epoch 471, Loss: 0.02289169281721115\n",
      "Epoch 472, Loss: 0.022805090993642807\n",
      "Epoch 473, Loss: 0.022718893364071846\n",
      "Epoch 474, Loss: 0.022632870823144913\n",
      "Epoch 475, Loss: 0.02254720777273178\n",
      "Epoch 476, Loss: 0.022461602464318275\n",
      "Epoch 477, Loss: 0.022376427426934242\n",
      "Epoch 478, Loss: 0.02229132317006588\n",
      "Epoch 479, Loss: 0.02220696210861206\n",
      "Epoch 480, Loss: 0.022122828289866447\n",
      "Epoch 481, Loss: 0.022038934752345085\n",
      "Epoch 482, Loss: 0.021955234929919243\n",
      "Epoch 483, Loss: 0.021871736273169518\n",
      "Epoch 484, Loss: 0.02178884670138359\n",
      "Epoch 485, Loss: 0.021706145256757736\n",
      "Epoch 486, Loss: 0.021624106913805008\n",
      "Epoch 487, Loss: 0.02154168300330639\n",
      "Epoch 488, Loss: 0.02146015502512455\n",
      "Epoch 489, Loss: 0.021378429606556892\n",
      "Epoch 490, Loss: 0.021297357976436615\n",
      "Epoch 491, Loss: 0.021216604858636856\n",
      "Epoch 492, Loss: 0.02113644964993\n",
      "Epoch 493, Loss: 0.02105584554374218\n",
      "Epoch 494, Loss: 0.02097601629793644\n",
      "Epoch 495, Loss: 0.02089679054915905\n",
      "Epoch 496, Loss: 0.020817989483475685\n",
      "Epoch 497, Loss: 0.020739048719406128\n",
      "Epoch 498, Loss: 0.020660391077399254\n",
      "Epoch 499, Loss: 0.020582599565386772\n",
      "Epoch 500, Loss: 0.020504595711827278\n",
      "Epoch 501, Loss: 0.020426852628588676\n",
      "Epoch 502, Loss: 0.020349375903606415\n",
      "Epoch 503, Loss: 0.020272139459848404\n",
      "Epoch 504, Loss: 0.020195497199892998\n",
      "Epoch 505, Loss: 0.02011852338910103\n",
      "Epoch 506, Loss: 0.020041760057210922\n",
      "Epoch 507, Loss: 0.01996557228267193\n",
      "Epoch 508, Loss: 0.019889770075678825\n",
      "Epoch 509, Loss: 0.019814573228359222\n",
      "Epoch 510, Loss: 0.019739147275686264\n",
      "Epoch 511, Loss: 0.019663767889142036\n",
      "Epoch 512, Loss: 0.01958908699452877\n",
      "Epoch 513, Loss: 0.01951432228088379\n",
      "Epoch 514, Loss: 0.019440246745944023\n",
      "Epoch 515, Loss: 0.019366245716810226\n",
      "Epoch 516, Loss: 0.019292423501610756\n",
      "Epoch 517, Loss: 0.01921921595931053\n",
      "Epoch 518, Loss: 0.019145991653203964\n",
      "Epoch 519, Loss: 0.019073164090514183\n",
      "Epoch 520, Loss: 0.019000928848981857\n",
      "Epoch 521, Loss: 0.018928347155451775\n",
      "Epoch 522, Loss: 0.0188563484698534\n",
      "Epoch 523, Loss: 0.018784822896122932\n",
      "Epoch 524, Loss: 0.018713323399424553\n",
      "Epoch 525, Loss: 0.018641676753759384\n",
      "Epoch 526, Loss: 0.01857081986963749\n",
      "Epoch 527, Loss: 0.018500028178095818\n",
      "Epoch 528, Loss: 0.018429510295391083\n",
      "Epoch 529, Loss: 0.018359361216425896\n",
      "Epoch 530, Loss: 0.01828940398991108\n",
      "Epoch 531, Loss: 0.018219752237200737\n",
      "Epoch 532, Loss: 0.01815059594810009\n",
      "Epoch 533, Loss: 0.018081309273838997\n",
      "Epoch 534, Loss: 0.018012790009379387\n",
      "Epoch 535, Loss: 0.017944471910595894\n",
      "Epoch 536, Loss: 0.01787613146007061\n",
      "Epoch 537, Loss: 0.017807770520448685\n",
      "Epoch 538, Loss: 0.017740318551659584\n",
      "Epoch 539, Loss: 0.017672721296548843\n",
      "Epoch 540, Loss: 0.017605459317564964\n",
      "Epoch 541, Loss: 0.01753820665180683\n",
      "Epoch 542, Loss: 0.017471525818109512\n",
      "Epoch 543, Loss: 0.017405498772859573\n",
      "Epoch 544, Loss: 0.017339492216706276\n",
      "Epoch 545, Loss: 0.017273439094424248\n",
      "Epoch 546, Loss: 0.017207864671945572\n",
      "Epoch 547, Loss: 0.017142513766884804\n",
      "Epoch 548, Loss: 0.017077529802918434\n",
      "Epoch 549, Loss: 0.017012320458889008\n",
      "Epoch 550, Loss: 0.016947796568274498\n",
      "Epoch 551, Loss: 0.01688366010785103\n",
      "Epoch 552, Loss: 0.016819609329104424\n",
      "Epoch 553, Loss: 0.016755692660808563\n",
      "Epoch 554, Loss: 0.01669175550341606\n",
      "Epoch 555, Loss: 0.016628460958600044\n",
      "Epoch 556, Loss: 0.01656545326113701\n",
      "Epoch 557, Loss: 0.016502201557159424\n",
      "Epoch 558, Loss: 0.01643957570195198\n",
      "Epoch 559, Loss: 0.016377517953515053\n",
      "Epoch 560, Loss: 0.01631484366953373\n",
      "Epoch 561, Loss: 0.016252944245934486\n",
      "Epoch 562, Loss: 0.01619117520749569\n",
      "Epoch 563, Loss: 0.01612972654402256\n",
      "Epoch 564, Loss: 0.016068557277321815\n",
      "Epoch 565, Loss: 0.016007335856556892\n",
      "Epoch 566, Loss: 0.01594673842191696\n",
      "Epoch 567, Loss: 0.015886470675468445\n",
      "Epoch 568, Loss: 0.015826448798179626\n",
      "Epoch 569, Loss: 0.015766402706503868\n",
      "Epoch 570, Loss: 0.015706412494182587\n",
      "Epoch 571, Loss: 0.015647010877728462\n",
      "Epoch 572, Loss: 0.01558772288262844\n",
      "Epoch 573, Loss: 0.015528110787272453\n",
      "Epoch 574, Loss: 0.015469280071556568\n",
      "Epoch 575, Loss: 0.015410532243549824\n",
      "Epoch 576, Loss: 0.015352210961282253\n",
      "Epoch 577, Loss: 0.015293760225176811\n",
      "Epoch 578, Loss: 0.01523550134152174\n",
      "Epoch 579, Loss: 0.015177394263446331\n",
      "Epoch 580, Loss: 0.015119874849915504\n",
      "Epoch 581, Loss: 0.015062387101352215\n",
      "Epoch 582, Loss: 0.015005280263721943\n",
      "Epoch 583, Loss: 0.014947823248803616\n",
      "Epoch 584, Loss: 0.014890890568494797\n",
      "Epoch 585, Loss: 0.014834214933216572\n",
      "Epoch 586, Loss: 0.014777807518839836\n",
      "Epoch 587, Loss: 0.014721524901688099\n",
      "Epoch 588, Loss: 0.014665688388049603\n",
      "Epoch 589, Loss: 0.014609843492507935\n",
      "Epoch 590, Loss: 0.014554249122738838\n",
      "Epoch 591, Loss: 0.014498726464807987\n",
      "Epoch 592, Loss: 0.014443505555391312\n",
      "Epoch 593, Loss: 0.014388811774551868\n",
      "Epoch 594, Loss: 0.014333554543554783\n",
      "Epoch 595, Loss: 0.014279067516326904\n",
      "Epoch 596, Loss: 0.014224676415324211\n",
      "Epoch 597, Loss: 0.014170456677675247\n",
      "Epoch 598, Loss: 0.014116492122411728\n",
      "Epoch 599, Loss: 0.014062628149986267\n",
      "Epoch 600, Loss: 0.014009150676429272\n",
      "Epoch 601, Loss: 0.013955885544419289\n",
      "Epoch 602, Loss: 0.013902736827731133\n",
      "Epoch 603, Loss: 0.01385018415749073\n",
      "Epoch 604, Loss: 0.01379743218421936\n",
      "Epoch 605, Loss: 0.013744885101914406\n",
      "Epoch 606, Loss: 0.013692435808479786\n",
      "Epoch 607, Loss: 0.013640609569847584\n",
      "Epoch 608, Loss: 0.013588960282504559\n",
      "Epoch 609, Loss: 0.013537213206291199\n",
      "Epoch 610, Loss: 0.013485370203852654\n",
      "Epoch 611, Loss: 0.013434168882668018\n",
      "Epoch 612, Loss: 0.013382798060774803\n",
      "Epoch 613, Loss: 0.01333164144307375\n",
      "Epoch 614, Loss: 0.013281119987368584\n",
      "Epoch 615, Loss: 0.013230618089437485\n",
      "Epoch 616, Loss: 0.013180406764149666\n",
      "Epoch 617, Loss: 0.013129877857863903\n",
      "Epoch 618, Loss: 0.01307986956089735\n",
      "Epoch 619, Loss: 0.013029864989221096\n",
      "Epoch 620, Loss: 0.012980446219444275\n",
      "Epoch 621, Loss: 0.01293092966079712\n",
      "Epoch 622, Loss: 0.012881709262728691\n",
      "Epoch 623, Loss: 0.01283289585262537\n",
      "Epoch 624, Loss: 0.012783963233232498\n",
      "Epoch 625, Loss: 0.012735451571643353\n",
      "Epoch 626, Loss: 0.012686806730926037\n",
      "Epoch 627, Loss: 0.01263880729675293\n",
      "Epoch 628, Loss: 0.012591015547513962\n",
      "Epoch 629, Loss: 0.012542962096631527\n",
      "Epoch 630, Loss: 0.01249514240771532\n",
      "Epoch 631, Loss: 0.012447644956409931\n",
      "Epoch 632, Loss: 0.012400428764522076\n",
      "Epoch 633, Loss: 0.012353199534118176\n",
      "Epoch 634, Loss: 0.01230631209909916\n",
      "Epoch 635, Loss: 0.012259397655725479\n",
      "Epoch 636, Loss: 0.012212743982672691\n",
      "Epoch 637, Loss: 0.012166256085038185\n",
      "Epoch 638, Loss: 0.012120198458433151\n",
      "Epoch 639, Loss: 0.012074184603989124\n",
      "Epoch 640, Loss: 0.012028491124510765\n",
      "Epoch 641, Loss: 0.011982688680291176\n",
      "Epoch 642, Loss: 0.011937007308006287\n",
      "Epoch 643, Loss: 0.011891490779817104\n",
      "Epoch 644, Loss: 0.011846404522657394\n",
      "Epoch 645, Loss: 0.011801482178270817\n",
      "Epoch 646, Loss: 0.011756489053368568\n",
      "Epoch 647, Loss: 0.01171157881617546\n",
      "Epoch 648, Loss: 0.011667108163237572\n",
      "Epoch 649, Loss: 0.011623026803135872\n",
      "Epoch 650, Loss: 0.011578893288969994\n",
      "Epoch 651, Loss: 0.011535374447703362\n",
      "Epoch 652, Loss: 0.011491531506180763\n",
      "Epoch 653, Loss: 0.011447628028690815\n",
      "Epoch 654, Loss: 0.011404003947973251\n",
      "Epoch 655, Loss: 0.011360595934092999\n",
      "Epoch 656, Loss: 0.011317258700728416\n",
      "Epoch 657, Loss: 0.011273941956460476\n",
      "Epoch 658, Loss: 0.01123135257512331\n",
      "Epoch 659, Loss: 0.011188664473593235\n",
      "Epoch 660, Loss: 0.011146430857479572\n",
      "Epoch 661, Loss: 0.01110425591468811\n",
      "Epoch 662, Loss: 0.011062384583055973\n",
      "Epoch 663, Loss: 0.011020584031939507\n",
      "Epoch 664, Loss: 0.010978523641824722\n",
      "Epoch 665, Loss: 0.0109367985278368\n",
      "Epoch 666, Loss: 0.010895311832427979\n",
      "Epoch 667, Loss: 0.010854178108274937\n",
      "Epoch 668, Loss: 0.010812783613801003\n",
      "Epoch 669, Loss: 0.010771723464131355\n",
      "Epoch 670, Loss: 0.010730890557169914\n",
      "Epoch 671, Loss: 0.010690252296626568\n",
      "Epoch 672, Loss: 0.010649611242115498\n",
      "Epoch 673, Loss: 0.010609167627990246\n",
      "Epoch 674, Loss: 0.01056869700551033\n",
      "Epoch 675, Loss: 0.010528945364058018\n",
      "Epoch 676, Loss: 0.010488766245543957\n",
      "Epoch 677, Loss: 0.010448493994772434\n",
      "Epoch 678, Loss: 0.010408611036837101\n",
      "Epoch 679, Loss: 0.010369082912802696\n",
      "Epoch 680, Loss: 0.010329469107091427\n",
      "Epoch 681, Loss: 0.01029028370976448\n",
      "Epoch 682, Loss: 0.010251360014081001\n",
      "Epoch 683, Loss: 0.01021252479404211\n",
      "Epoch 684, Loss: 0.01017397828400135\n",
      "Epoch 685, Loss: 0.010135574266314507\n",
      "Epoch 686, Loss: 0.01009704265743494\n",
      "Epoch 687, Loss: 0.010058761574327946\n",
      "Epoch 688, Loss: 0.010020866058766842\n",
      "Epoch 689, Loss: 0.009982949122786522\n",
      "Training finished. Final error: 0.009982949122786522\n"
     ]
    }
   ],
   "source": [
    "# Обучение с условием выхода\n",
    "desired_error = 0.01\n",
    "current_error = float('inf')\n",
    "num_epochs = 0\n",
    "\n",
    "while current_error > desired_error:\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Смотрим ошибку на тестовой выборке данных\n",
    "    with torch.no_grad():\n",
    "        all_outputs = model(x_test_tensor)\n",
    "        total_loss = criterion(all_outputs, y_test_tensor)\n",
    "\n",
    "    current_error = total_loss.item()\n",
    "    num_epochs += 1\n",
    "    print(f'Epoch {num_epochs}, Loss: {current_error}')\n",
    "\n",
    "print(f'Training finished. Final error: {current_error}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T10:24:37.426656Z",
     "start_time": "2023-12-16T10:24:35.262191Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Предсказания для тестового набора данных\n",
    "with torch.no_grad():\n",
    "    predictions = model(x_test_tensor)\n",
    "\n",
    "# Преобразование предсказаний в бинарные метки (0 или 1)\n",
    "binary_predictions = (predictions >= 0.5).float()\n",
    "# Преобразование меток тестового набора в бинарные метки (если необходимо)\n",
    "binary_labels = (y_test_tensor >= 0.5).float()\n",
    "\n",
    "accuracy = accuracy_score(binary_labels.numpy(), binary_predictions.numpy())\n",
    "print(f'Accuracy: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T10:24:37.440581Z",
     "start_time": "2023-12-16T10:24:37.427896Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Веса первого слоя:\n",
      "h11: [[-0.6401693  -0.00475632]] [-0.20022073]\n",
      "h12: [[0.46414253 0.5485788 ]] [-0.11378223]\n",
      "\n",
      "Веса второго слоя:\n",
      "h21: [[ 0.3987472  -0.51611125]] [0.37415844]\n",
      "h22: [[-0.26039526 -0.47334513]] [0.32202435]\n",
      "h23: [[ 0.3911116  -0.40017655]] [-0.47521725]\n",
      "\n",
      "Веса третьего слоя:\n",
      "w1: [-0.05555632]\n",
      "w2: [0.60394126]\n",
      "w3: [-0.6154566]\n"
     ]
    }
   ],
   "source": [
    "# значения смещения (bias) для слоя\n",
    "print(\"\\nВеса первого слоя:\")\n",
    "print(\"h11:\", model.h11.weight.data.numpy(), model.h11.bias.data.numpy())\n",
    "print(\"h12:\", model.h12.weight.data.numpy(), model.h12.bias.data.numpy())\n",
    "\n",
    "print(\"\\nВеса второго слоя:\")\n",
    "print(\"h21:\", model.h21.weight.data.numpy(), model.h21.bias.data.numpy())\n",
    "print(\"h22:\", model.h22.weight.data.numpy(), model.h22.bias.data.numpy())\n",
    "print(\"h23:\", model.h23.weight.data.numpy(), model.h23.bias.data.numpy())\n",
    "\n",
    "print(\"\\nВеса третьего слоя:\")\n",
    "print(\"w1:\", model.w1.data.numpy())\n",
    "print(\"w2:\", model.w2.data.numpy())\n",
    "print(\"w3:\", model.w3.data.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T10:24:37.486868Z",
     "start_time": "2023-12-16T10:24:37.439986Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xj/zsznjkrj1xj89f8v149z8v7h0000gp/T/ipykernel_52419/3229853656.py:9: UserWarning: You passed a edgecolor/edgecolors ('r') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  plt.scatter(x_test[:, 0], x_test[:, 1], c=predictions.flatten(), cmap=plt.cm.Paired, marker='x', edgecolor='r', label='Предсказанные значения')\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Предсказания для тестового набора данных\n",
    "with torch.no_grad():\n",
    "    predictions = model(x_test_tensor).numpy()\n",
    "\n",
    "plt.scatter(x_test[:, 0], x_test[:, 1], c=y_test.flatten(), cmap=plt.cm.Paired, edgecolor='k', label='Исходные значения')\n",
    "plt.scatter(x_test[:, 0], x_test[:, 1], c=predictions.flatten(), cmap=plt.cm.Paired, marker='x', edgecolor='r', label='Предсказанные значения')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T10:24:37.634214Z",
     "start_time": "2023-12-16T10:24:37.455520Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T10:24:37.635075Z",
     "start_time": "2023-12-16T10:24:37.629870Z"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
